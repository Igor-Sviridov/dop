{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Остаточные нейронные сети (Residual Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Деградация обучения глубоких нейронных сетей\n",
    "\n",
    "При рассмотрении развития архитектур сверточных нейронных сетей можно увидеть, что существовала тенденция к увеличению количества слоев.\n",
    "\n",
    "* Важным преимуществом очень глубокой сети состоит в том, что она может аппроксимировать сложные функции.\n",
    "  \n",
    "* Однако использование более глубокой сети не всегда помогает. Как показала практика, обучению мешает проблема исчезающих градиентов: в очень глубоких сетях значение градиента быстро достигает нуля, что делает градиентный спуск крайне медленным.\n",
    "\n",
    "* Иногда возможны ситуации, когда вместо затухания градиентов происходит обратная ситуация - их значения становятся крайне большими и случается \"взрыв градиентов\" - их резкий рост.\n",
    "\n",
    "* Таким образом, во время обучения может случиться ситуация, когда скорость обучения первых слоев нейронной сети спадает к очень маленьким значениям:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<caption><center><img src=\"images/vanishing_grad_kiank.png\" style=\"width:450px;height:220px;\"></center></caption>\n",
    "<caption><center><b> Рисунок 1 : <b>Проблема исчезающих градиентов</b>   </center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Построение ResNet\n",
    "\n",
    "В ResNets, применяются соединения, позволяющие модели пропускать один или несколько слоев. Их называют \"shortcut\" или \"skip connection\":  \n",
    "\n",
    "<caption><center><img src=\"images/skip_connection_kiank.png\" style=\"width:650px;height:200px;\"></center></caption>\n",
    "<caption><center><b> Рисунок 2 : Shortcut соединение</b>   </center></caption>\n",
    "\n",
    "Левое изображение показывает стандартное соединение нейронной сети. На правом изображении введено соединение, позволяющее пропустить выходные значения одного из слоев. Такая структура позволяет некоторым слоям после обучения соответствовать функции тождественного отображения, а значит увеличение слоев не приведет к ухудшению процесса обучения.\n",
    " \n",
    "Для построения сверточной нейронной сети ResNet используется два основных типа блока. Один из них применяется в случае, когда выходные и входные размеры тензоров не изменяются (identity block), а второй (convocational block) - в обратном случае. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 - Identity Block\n",
    "\n",
    "Рассмотрим стуктуру этого блока:\n",
    "\n",
    "<caption><center><img src=\"images/idblock2_kiank.png\" style=\"width:650px;height:150px;\"> </center></caption>\n",
    "<caption><center><b> Рисунок 3 : Identity block</b>   </center></caption>\n",
    "\n",
    "Как видно из рисунка 3, существует два пути: основной и Shortcut. После каждого сверточного слоя выполняется функция активации. Кроме того, для ускорения обучения применяются слои пакетной нормализации (BatchNorm).\n",
    "\n",
    "Далее мы реализуем модифицированную версию identity блока, в которой Shortcut соединение пропускает сразу три скрытых слоя. Такая структура показана на рисунке 4.\n",
    "\n",
    "<caption><center> <img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\"> </center></caption>\n",
    "<caption><center><b> Рисунок 4 : Identity block, модифицированная версия </b>   </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим составляющие identity блока:\n",
    "\n",
    "Первая часть основного пути:\n",
    "\n",
    "- Первый слой CONV2D имеет фильтры $F_1$ с размерностями (1,1) и размером шага (1,1). Padding - \"valid\". Для инициализации весов используйте seed = 0 и равномерное распределение  `kernel_initializer = Initializer(seed=0)`.\n",
    "- В первом слое BatchNorm нормализация выполняется по размерности «каналы».\n",
    "- Затем применяется функцию активации ReLU. \n",
    "\n",
    "Вторая часть основного пути:\n",
    "\n",
    "- Второй слой CONV2D имеет фильтры $F_2$ с размерностями (f,f) и размером шага (1,1). Padding - \"same\". Для инициализации весов используйте seed = 0 и равномерное распределение  `kernel_initializer = Initializer(seed=0)`.\n",
    "- Во втором слое BatchNorm нормализация выполняется по размерности «каналы».\n",
    "- Затем применяется функцию активации ReLU. \n",
    "\n",
    "Третья часть основного пути:\n",
    "\n",
    "- Третий слой CONV2D имеет фильтры $F_3$ с размерностями (1,1) и размером шага (1,1). Padding - \"valid\". Для инициализации весов используйте seed = 0 и равномерное распределение  `kernel_initializer = Initializer(seed=0)`.\n",
    "- Во втором слое BatchNorm нормализация выполняется по размерности «каналы».\n",
    "- Обратите внимание, на данном этапе функция активации не применяется.\n",
    "\n",
    "Shortcut соединение:\n",
    "\n",
    "- Далее выполняется сложение `X_shortcut` и выхода третьего слоя `X`.\n",
    "- Для выполнения сложения тензоров используется следующий синтаксис `Add()([var1,var2])`\n",
    "- Далее применяется функция активации ReLU. \n",
    "\n",
    "Документация:\n",
    "\n",
    "- Документация для функции [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "- Документация для функции [BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) `BatchNormalization(axis = 3)(X, training = training)`. Если параметр training установлен в значение False, его веса не будут изменяться. Это используется, когда модель применяется в режиме выполнения предсказаний, а не обучения.\n",
    "- Для применения функции активации используйте  `Activation('relu')(X)`\n",
    "- Документация для функции [Add](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add)\n",
    "\n",
    "Кроме того, мы передаем в функцию тип инициализации весов [tensorflow.keras.initializers](https://www.tensorflow.org/api_docs/python/tf/keras/initializers). По умолчанию используется [random_uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/RandomUniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0017b68317ffa974",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    Реализация структуры, изображенной на рисунке 4\n",
    "    \n",
    "    Аргументы:\n",
    "    X -- входной тензор с размерностями (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- целое число, задает размер фильтра в середине структуры\n",
    "    filters -- список python, содержащий целые числа. определяет количество фильтров в сверточных слоях блока\n",
    "    training -- True: Режим обучения\n",
    "                False: Режим выполнения предсказаний\n",
    "    initializer -- тип инициализации весов\n",
    "    \n",
    "    Выходные значения:\n",
    "    X -- выходной тензор с размерностями (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Получение количества фильтров\n",
    "    F1, F2, F3 = ...\n",
    "    \n",
    "    # Сохранение входного значения \n",
    "    X_shortcut = ...\n",
    "    \n",
    "    # Первая часть основного пути\n",
    "    ## padding = 'valid'\n",
    "    X = Conv2D(filters=F1, kernel_size=1, strides=(1,1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = ...\n",
    "    \n",
    "    # Вторая часть основного пути\n",
    "    ## padding = 'same'\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "\n",
    "    # Третья часть основного пути\n",
    "    ## padding = 'valid'\n",
    "    X = ...\n",
    "    X = ...\n",
    "    \n",
    "    ## Выполнение сложения и применение функции активации\n",
    "    X = ...\n",
    "    X = ...\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e73a8466b807e261",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "\n",
    "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1),\n",
    "                   training=False)\n",
    "print('\\033[1mWith training=False\\033[0m\\n')\n",
    "A3np = A3.numpy()\n",
    "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
    "print(resume[1, 1, 0])\n",
    "\n",
    "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
    "np.random.seed(1)\n",
    "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1),\n",
    "                   training=True)\n",
    "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый вывод**\n",
    "\n",
    "```\n",
    "With training=False\n",
    "\n",
    "[[[  0.        0.        0.        0.     ]\n",
    "  [  0.        0.        0.        0.     ]]\n",
    "\n",
    " [[192.71234 192.71234 192.71234  96.85617]\n",
    "  [ 96.85617  96.85617  96.85617  48.92808]]\n",
    "\n",
    " [[578.1371  578.1371  578.1371  290.5685 ]\n",
    "  [290.5685  290.5685  290.5685  146.78426]]]\n",
    "96.85617\n",
    "\n",
    "With training=True\n",
    "\n",
    "[[[0.      0.      0.      0.     ]\n",
    "  [0.      0.      0.      0.     ]]\n",
    "\n",
    " [[0.40739 0.40739 0.40739 0.40739]\n",
    "  [0.40739 0.40739 0.40739 0.40739]]\n",
    "\n",
    " [[4.99991 4.99991 4.99991 3.25948]\n",
    "  [3.25948 3.25948 3.25948 2.40739]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - Convolutional Block\n",
    "\n",
    "Рассмотрим второй тип блока. Он применяется в случае, когда выходная и выходная размерность тензоров не совпадает. Отличием от identity блока является наличие слоя CONV2D в shortcut соединении. \n",
    "\n",
    "<caption><center><img src=\"images/convblock_kiank.png\" style=\"width:650px;height:150px;\"></center></caption>\n",
    "<caption><center><b> Рисунок 5 : Convolutional block </b>   </center></caption>\n",
    "\n",
    "* Слой CONV2D в shortcut соединении нужен для изменения размерности тензора с целью выполнения соответствия размерностей с выходным тензором основного пути. \n",
    "* За слоем CONV2D в shortcut соединении не применяется функция активации. \n",
    "* В данном блоке используется аргумент `initializer` со значением [glorot_uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform)\n",
    "\n",
    "Рассмотрим составляющие convolutional блока:\n",
    "\n",
    "Первая часть основного пути:\n",
    "\n",
    "- Первый слой CONV2D имеет фильтры $F_1$ с размерностями (1,1) и размером шага (s,s). Padding - \"valid\". Для инициализации весов используйте seed = 0 `kernel_initializer = Initializer(seed=0)` и распределение `glorot_uniform`.\n",
    "- В первом слое BatchNorm нормализация выполняется по размерности «каналы».\n",
    "- Затем применяется функцию активации ReLU. \n",
    "\n",
    "Вторая часть основного пути:\n",
    "\n",
    "- Второй слой CONV2D имеет фильтры $F_2$ с размерностями (f,f) и размером шага (1,1). Padding - \"same\". Для инициализации весов используйте seed = 0 `kernel_initializer = Initializer(seed=0)` и распределение `glorot_uniform`.\n",
    "- Во втором слое BatchNorm нормализация выполняется по размерности «каналы».\n",
    "- Затем применяется функцию активации ReLU. \n",
    "\n",
    "Третья часть основного пути:\n",
    "\n",
    "- Третий слой CONV2D имеет фильтры $F_3$ с размерностями (1,1) и размером шага (s,s). Padding - \"valid\". Для инициализации весов используйте seed = 0 `kernel_initializer = Initializer(seed=0)` и распределение `glorot_uniform`.\n",
    "- Во втором слое BatchNorm нормализация выполняется по размерности «каналы».\n",
    "- Обратите внимание, на данном этапе функция активации не применяется.\n",
    "\n",
    "Shortcut соединение:\n",
    "- Применяется слой CONV2D, который имеет фильтры $F_3$ с размерностями (1,1) и размером шага (s,s). Padding - \"valid\". Для инициализации весов используйте seed = 0 `kernel_initializer = Initializer(seed=0)` и распределение `glorot_uniform`.\n",
    "- Далее выполняется сложение `X_shortcut` и выхода третьего слоя `X`.\n",
    "- Для выполнения сложения тензоров используется следующий синтаксис `Add()([var1,var2])`\n",
    "- Далее применяется функция активации ReLU. \n",
    "\n",
    "Документация:\n",
    "\n",
    "- Документация для функции [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "- Документация для функции [BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) `BatchNormalization(axis = 3)(X, training = training)`. Если параметр training установлен в значение False, его веса не будут изменяться. Это используется, когда модель применяется в режиме выполнения предсказаний, а не обучения.\n",
    "- Для применения функции активации используйте  `Activation('relu')(X)`\n",
    "- Документация для функции [Add](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df47af4847e5335f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    Реализация структуры, изображенной на рисунке 5\n",
    "    \n",
    "    Аргументы:\n",
    "    X -- входной тензор с размерностями (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- целое число, задает размер фильтра в середине структуры\n",
    "    filters -- список python, содержащий целые числа. определяет количество фильтров в сверточных слоях блока\n",
    "    s -- целое число, задает размер шага свертки в блоке\n",
    "    training -- True: Режим обучения\n",
    "                False: Режим выполнения предсказаний\n",
    "    initializer -- тип инициализации весов. По умолчанию используется Glorot uniform инициализация,\n",
    "                   которую также называют Xavier uniform.\n",
    "    \n",
    "    Выходные значения:\n",
    "    X -- выходной тензор с размерностями (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Получение количества фильтров\n",
    "    F1, F2, F3 = ...\n",
    "    \n",
    "    # Сохранение входного значения \n",
    "    X_shortcut = ...\n",
    "    \n",
    "    # Первая часть основного пути\n",
    "    ## glorot_uniform(seed=0)\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "    \n",
    "    # Вторая часть основного пути\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "\n",
    "    # Третья часть основного пути\n",
    "    X = ...\n",
    "    X = ...\n",
    "    \n",
    "    # Свертка в shortcut соединении\n",
    "    X_shortcut = ...  \n",
    "    X_shortcut = ...\n",
    "\n",
    "    # Выполнение сложения и применение функции активации\n",
    "    X = ...\n",
    "    X = ...\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-95c291eb244218fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "\n",
    "A = convolutional_block(X, f = 2, filters = [2, 4, 6], training=False)\n",
    "\n",
    "assert type(A) == EagerTensor, \"Use only tensorflow and keras functions\"\n",
    "assert tuple(tf.shape(A).numpy()) == (3, 2, 2, 6), \"Wrong shape.\"\n",
    "print(A[0])\n",
    "\n",
    "B = convolutional_block(X, f = 2, filters = [2, 4, 6], training=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый вывод**\n",
    "\n",
    "```\n",
    "tf.Tensor(\n",
    "[[[0.         0.66683817 0.         0.         0.88853896 0.5274254 ]\n",
    "  [0.         0.65053666 0.         0.         0.89592844 0.49965227]]\n",
    "\n",
    " [[0.         0.6312079  0.         0.         0.8636247  0.47643146]\n",
    "  [0.         0.5688321  0.         0.         0.85534114 0.41709304]]], shape=(2, 2, 6), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>  \n",
    "## 4 - Построение модели ResNet (50 слоев)\n",
    "\n",
    "Архитектура сети представлена на рисунке 6. Обозначение \"ID BLOCK\" отвечает за \"Identity block,\" а \"x3\" означает 3 последовательно идущих друг за другом блока.\n",
    "\n",
    "<caption><img src=\"images/resnet_kiank.png\" style=\"width:850px;height:150px;\"></center></caption>\n",
    "<caption><center><b> Рисунок 6 : ResNet-50 </b>   </center></caption>\n",
    "\n",
    "Архитектура ResNet-50:\n",
    "- Входной тензор дополняется нулями (3,3) (по три нуля с каждой стороны)\n",
    "- Часть 1:\n",
    "    - Слой 2D Convolution с 64 фильтрами размером (7,7), шаг свертки (2,2). \n",
    "    - Слой BatchNorm, нормализация по размерности 'channels'.\n",
    "    - Функция активации ReLU.\n",
    "    - MaxPooling с размером окна (3,3) и шагом (2,2).\n",
    "- Часть 2:\n",
    "    - Convolutional блок, три набора фильтров по [64,64,256] фильтра соответственно, параметр \"f\" равен 3, параметр \"s\" равен 1.\n",
    "    - Далее следует 2 identity блока, в каждом три набора фильтров по [64,64,256] фильтра соответственно, параметр \"f\" равен 3.\n",
    "- Часть 3:\n",
    "    - Convolutional блок, три набора фильтров по [128,128,512] фильтра соответственно, параметр \"f\" равен 3, параметр \"s\" равен 2.\n",
    "    - Далее следует 3 identity блока, в каждом три набора фильтров по [128,128,512] фильтра соответственно, параметр \"f\" равен 3.\n",
    "- Часть 4:\n",
    "    - Convolutional блок, три набора фильтров по [256, 256, 1024] фильтра соответственно, параметр \"f\" равен 3, параметр \"s\" равен 2.\n",
    "    - Далее следует 5 identity блоков, в каждом три набора фильтров по [256, 256, 1024] фильтра соответственно, параметр \"f\" равен 3.\n",
    "- Часть 5:\n",
    "    - Convolutional блок, три набора фильтров по [512, 512, 2048] фильтра соответственно, параметр \"f\" равен 3, параметр \"s\" равен 2.\n",
    "    - Далее следует 2 identity блока, в каждом три набора фильтров по [512, 512, 2048] фильтра соответственно, параметр \"f\" равен 3.\n",
    "- Далее применяется слой 2D Average Pooling, размер окна (2,2).\n",
    "- Далее используется слой 'flatten'.\n",
    "- Наконец, применяется полносвязый слой (Dense), количество нейронов равно количеству выходных классов.\n",
    "\n",
    "    \n",
    "Документация: \n",
    "- Average pooling [see reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D)\n",
    "- Conv2D: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "- BatchNorm: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) \n",
    "- Zero padding: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding2D)\n",
    "- Max pooling: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)\n",
    "- Fully connected layer: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "- Addition: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10dc95a4cf6275b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Имплементация архитектуры ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Аргументы:\n",
    "    input_shape -- размер изображений в датасете\n",
    "    classes -- целое число, количество классов\n",
    "\n",
    "    Returns:\n",
    "    model -- класс Model() из Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Устанавливаем входной тензор с размерностью input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ...\n",
    "    \n",
    "    # Часть 1\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "\n",
    "    # Часть 2\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "    \n",
    "    ## Часть 3\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "    \n",
    "    ## Часть 4\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "\n",
    "    ## Часть 5\n",
    "    X = ...\n",
    "    X = ...\n",
    "    X = ...\n",
    "\n",
    "    ## AVGPOOL. используйте \"X = AveragePooling2D(...)(X)\"\n",
    "    X = ...\n",
    "\n",
    "    # выходной слой\n",
    "    X = ...\n",
    "    X = ...\n",
    "    \n",
    "    \n",
    "    # Создание модели\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-866b891ec47ccb7b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "model.summary()\n",
    "# Ожидаемый результат представлен в файле result.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компиляция модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь все готово для обучения. Используем датасет из Simple_CNN. Самостоятельно допишите код, который загрузит датасет с цифрами и поделит его на части (аналогично Simple_CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель на 10 эпохах с размером батча 32. При обучении на CPU можно сократить до 5-6 эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка модели на тестовом датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>  \n",
    "## 5 - Проверка модели на своем изображении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте работу нейронной сети на своем изображении. Для этого сделайте фотографию и подайте ее на вход нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'photo.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255.0\n",
    "print('Input image shape:', x.shape)\n",
    "imshow(img)\n",
    "prediction = model.predict(x)\n",
    "print(\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \", prediction)\n",
    "print(\"Class:\", np.argmax(prediction))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
